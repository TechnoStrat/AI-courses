{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cet exercice est de construire une IA capable de reconnaître des chiffres manuscrits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 - Comprendre les données utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les librairies qui nous seront utiles pour résoudre le problème :  \n",
    "- __MNIST__ : pour l'import de la base de données MNIST contenant 100.000 chiffres manuscrits  \n",
    "- __Numpy__ : pour travailler facilement des tableaux / matrices de données  \n",
    "- __Matplotlib.pyplot__ : pour faire des graphiques    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les données du use case :\n",
    "- un dataset de données __images_train__ et __labels_train__ qu'on utilisera pour l'entraînement de l'intelligence artificielle\n",
    "- un dataset de données __images_test__ et __labels_test__ qu'on utilisera pour tester l'intelligence artificielle    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "mndata = MNIST('./Resources')\n",
    "images_train, labels_train = mndata.load_training()\n",
    "images_test, labels_test = mndata.load_testing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"blue\">Q1.1 : Que représentent les données __images_train__ et __labels_train__ ? Idem pour __images_test__ et __labels_test__.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type de images_train : <class 'list'>\n",
      "Type de labels_train : <class 'array.array'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type de images_train : \" + str(type(images_train)))\n",
    "print(\"Type de labels_train : \" + str(type(labels_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'éléments dans images_train : 60000\n",
      "Nombre d'éléments dans labels_train : 60000\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre d'éléments dans images_train : \" + str(len(images_train)))\n",
    "print(\"Nombre d'éléments dans labels_train : \" + str(len(labels_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type d'un élément de images_train : <class 'list'>\n",
      "Type d'un élément de labels_train : <class 'int'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Type d'un élément de images_train : \" + str(type(images_train[0])))\n",
    "print(\"Type d'un élément de labels_train : \" + str(type(labels_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type d'un élément d'un élément de images_train : <class 'int'>\n",
      "Nombre d'éléments d'un élément de images_train : 784\n"
     ]
    }
   ],
   "source": [
    "print(\"Type d'un élément d'un élément de images_train : \" + str(type(images_train[0][0])))\n",
    "print(\"Nombre d'éléments d'un élément de images_train : \" + str(len(images_train[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de représentation d'un élément de images_train : [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 18, 18, 18, 126, 136, 175, 26, 166, 255, 247, 127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 36, 94, 154, 170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 238, 253, 253, 253, 253, 253, 253, 253, 253, 251, 93, 82, 82, 56, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 219, 253, 253, 253, 253, 253, 198, 182, 247, 241, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 80, 156, 107, 253, 253, 205, 11, 0, 43, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 1, 154, 253, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 139, 253, 190, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 190, 253, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 241, 225, 160, 108, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 240, 253, 253, 119, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 186, 253, 253, 150, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 93, 252, 253, 187, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 249, 253, 249, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 130, 183, 253, 253, 207, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 148, 229, 253, 253, 253, 250, 182, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 114, 221, 253, 253, 253, 253, 201, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 66, 213, 253, 253, 253, 253, 198, 81, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 171, 219, 253, 253, 253, 253, 195, 80, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 55, 172, 226, 253, 253, 253, 253, 244, 133, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 136, 253, 253, 253, 212, 135, 132, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Exemple de label d'un élément de labels_train : 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemple de représentation d'un élément de images_train : \" + str(images_train[0]))\n",
    "print(\"Exemple de label d'un élément de labels_train : \" + str(labels_train[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données d'entraînement et de test sont composés de :\n",
    "- une liste d'images représentant chacune un chiffre manuscrit images_train (pour l'entraînement), images_test (pour le test)\n",
    "- une liste de labels représentant chacun le chiffre que le manuscrit est censé représenté labels_train (pour l'entraînement), labels_test (pour le test)\n",
    "\n",
    "Chaque image est représentée par une liste de 784 valeurs comprises entre 0 et 255. Chaque valeur représente l'intensité d'un pixel de l'image (0 = noir, 255 = blanc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_num = np.random.randint(0,n_train)\n",
    "random_image = images_train[random_num]\n",
    "n_pxl = len(random_image)\n",
    "print(\"Nombre de pixels : \" + str(n_pxl))\n",
    "print(\"Exemple de représentation d'une donnée : \" + str(random_image))\n",
    "print(\"Exemple de label d'une image : \" + str(labels_train[random_num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rendre l'affichage d'une de ces données plus lisible pour un humain, on procède de la manière suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on sélectionne une donnée au hasard parmi les données d'entraînement\n",
    "random_num = np.random.randint(0,n_train)\n",
    "random_image = images_train[random_num]\n",
    "\n",
    "def aff_image(image, title, ax = None): \n",
    "    # on recompose l'image sous forme de tableau contenant 28x28 pixels (car 28x28 = 784)\n",
    "    # et on crée un graphique pour l'afficher\n",
    "    image_reshape = np.array(image).reshape(28,28, order='C')\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(1,1)\n",
    "    ax.imshow(image_reshape, cmap='gray')\n",
    "    ax.set_title(title)\n",
    "\n",
    "# on rajoute le label en titre et on affiche le graphique\n",
    "aff_image(image = random_image, \\\n",
    "          title = \"Label : \" + str(labels_train[random_num]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de passer à la partie suivante, il est toujours bon de s'assurer que nos échantillons sont bien représentatifs. Pour cela, on affiche la distribution des chiffres manuscrits dans nos échantillons de test et d'entraînement.\n",
    "Quel constat pouvons-nous faire ici ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,6))\n",
    "plt.hist([labels_train, labels_test], bins = np.arange(0,11) - 0.5, ec='black', \\\n",
    "        weights=[np.ones(len(labels_train)) / len(labels_train), np.ones(len(labels_test)) / len(labels_test)], \\\n",
    "        label = [\"Entraînement\", \"Test\"])\n",
    "plt.xlabel(\"Chiffres manuscrits\")\n",
    "plt.ylabel(\"Fréquence d'occurrence\")\n",
    "plt.xticks(range(0,10))\n",
    "plt.title(\"Distribution des échantillons\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, on peut construire l'image moyenne de nos échantillons pour se donner une idée de la diversité des échantillons. Que peut-on en déduire ici ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on construit l'image moyenne des échantillons d'entraînement et de test\n",
    "# chaque pixel de cette image représente la moyenne des mêmes pixels de chaque image de l'échantillon\n",
    "average_image_train = [sum([image[i] for image in images_train])/len(images_train) for i in range(0,784)]\n",
    "average_image_test = [sum([image[i] for image in images_test])/len(images_test) for i in range(0,784)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on affiche chacune des images moyennes ainsi calculées\n",
    "f, axis = plt.subplots(1,2, figsize=(10,5))\n",
    "aff_image(image = average_image_train, \\\n",
    "          title = \"Image moyenne (échantillon d'entraînement)\", \\\n",
    "          ax = axis[0])\n",
    "aff_image(image = average_image_test, \\\n",
    "          title = \"Image moyenne (échantillon de test)\", \\\n",
    "          ax = axis[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 - Construction d'un réseau de neurones artificiels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de parler des réseaux de neurones artificiels, introduisons ce qu'est un neurone formel. Un neurone formel prend en entrée un certain nombre de données i1, ... in auxquelles il applique des coefficients ou poids w1, ... wn, qu'il apprend à définir lui-même. Il en fait ensuite la somme et il applique au résultat ainsi obtenu une fonction d'activation (non linéaire).\n",
    "Pour comprendre à quoi peut servir un neurone formel, prenons un exemple. Supposons qu'on souhaite prédire si un consultant va démissionner dans le prochain mois. On considère que les données qui peuvent être utilisées pour prédire ce résultat sont : le nombre de formations suivies lors du dernier trimestre, la distance moyenne de ses derniers clients par rapport à Paris, son grade, son salaire et son sexe. On construit un échantillon d'entraînement (disons de 1000 consultants) et on envoie chacune de ces données dans un neurone formel.\n",
    "Le neurone va prendre en entrée ces 5 paramètres i1, i2, i3, i4, i5 et calculer les poids associés w1, w2, w3, w4, w5. Au début il ne saura pas comment choisir ces poids et le fera au hasard. Pour le premier consultant qu'il verra (disons qu'il n'ait pas démissionné), il choisira peut-être que tous les poids valent 1. Il passera donc la somme i1 + ... + i5 dans la fonction d'activation qui sortira un résultat compris entre 0 et 1, disons 0,8. On considère que si le résultat est supérieur à 0,5 alors le consultant va démissionner. Donc sur ce cas, le neurone s'est trompé. Il va alors adapter les paramètres w1, ..., w5 pour se conformer à ce résultat. Il va ensuite regarder le cas du deuxième consultant et appliqué le même procédé. Au fil des consultants vus, le neurone va de plus en plus finement adapter ses poids w1, ... w5. Au bout de 1000 consultants, normalement les poids devraient être optimisés pour qu'il parvienne à prédire correctement le résultat sur un nombre de cas significatifs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Resources/Neurone.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un seul neurone formel n'est souvent pas suffisant pour obtenir de bons résultats car le neurone formel ne calcule des poids que sur chaque paramètre d'entrée pris individuellement. Or parfois, c'est bien la combinaison de paramètres en entrée qui peut faciliter la prédiction (par exemple la combinaison âge du consultant et distance de sa dernière mission par rapport à Paris). On construit donc une architecture de neurones formels qui va multiplier les combinaisons des paramètres d'entrée. Chaque neurone peut alors envoyer son résultat à d'autres neurones si le réseau est constitué de plusieurs couches. Cette architecture, un peu \"bourrine\", est toutefois redoutablement efficace !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Exemple de réseau de neurones à deux couches](Resources/Réseau de neurones.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette partie vise à construire un réseau de neurones artificiels pour prédire le chiffre manuscrit présent sur une image. Les données envoyées en entrée de l'algorithme seront les pixels des images de nos bases de données et la sortie sera le label de l'image (le chiffre représenté sur l'image). Il y a ura donc 784 données en entrée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, on importe les librairies dont on aura besoin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras # librairie facile à utiliser pour créer des réseaux de neurones artificiels \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras import optimizers\n",
    "from sklearn import preprocessing # librairie utilisée pour normaliser les données en entrée du problème\n",
    "from sklearn.preprocessing import OneHotEncoder # pour modifier le format des labels\n",
    "from sklearn.metrics import accuracy_score # pour mesurer la performance de l'IA\n",
    "import random # pour sélectionner des nombres aléatoirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement, on ne peut pas envoyer les pixels tels quels dans le réseau de neurones, car il faut que les valeurs envoyées en entrée soient toutes strictement comparables. Si on reprend l'exemple de la prédiction du consultant qui va démissionner. L'âge et le salaire ne sont pas des données strictement comparables car le salaire est souvent bien plus élevé que l'âge. Le réseau de neurones sera donc beaucoup plus sensible au salaire qu'à l'âge. (une variation de 10 ans d'âge ne sera rien comparée à une variation de 1000€ de salaire).\n",
    "Un moyen simple d'éviter ce problème est de centrer toutes les valeurs autour de 0 et de les \"normer\" pour quel majorité d'entre elles aient une valeur comprise entre -1 et 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On centre donc toutes les valeurs de pixels autour de 0 et on les normalise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "normalized_images_train = scaler.fit_transform(images_train)\n",
    "normalized_images_test = scaler.transform(images_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La majorité des pixels ont maintenant une valeur comprise entre -1 et 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# on sélectionne une donnée au hasard parmi les données d'entraînement et on l'affiche\n",
    "random_num = np.random.randint(0,n_train)\n",
    "print(normalized_images_train[random_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernière étape avant de pouvoir construire notre réseau de neurones. il va falloir changer la manière donc sont labellisés les images ! En effet, un réseau de neurones artificiels sort toujours une probabilité. Ici il sortira donc la probabilité que l'image représente un 0, un 1, un 2, ... ou un 9. Ce sera donc une liste de 10 probabilité et on considérera que le chiffre représenté sur l'image sera celui ayant la plus haute probabilité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi si dans les données d'entraînement, on indique au réseau de neurones que le chiffre représenté sur l'image est un 9, il ne comprendra pas (car ce n'est pas une liste contenant 10 probabilités). En revanche il comprendra si on lui donne la liste [0,0,0,0,0,0,0,0,0,1] (tous les chiffres ont une probabilité de 0, sauf le dernier (le 9) qui a une probabilité de 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va donc transformer tous les labels pour qu'ils soient des listes de 10 probabilités."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder()\n",
    "encoded_labels_train = onehotencoder.fit_transform(np.array(labels_train).reshape(-1,1)).toarray()\n",
    "encoded_labels_test = onehotencoder.transform(np.array(labels_test).reshape(-1,1)).toarray()\n",
    "\n",
    "# on vérifie le résultat\n",
    "random_num = np.random.randint(0,10000)\n",
    "print(\"Le label d'entraînement \" + str(labels_train[random_num]) + \" a été encodé en \" + str(encoded_labels_train[random_num]))\n",
    "print(\"Le label de test \" + str(labels_test[random_num]) + \" a été encodé en \" + str(encoded_labels_test[random_num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On est enfin prêt pour créer notre réseau de neurones artificiels. On aura donc n=784 données principalement comprises entre -1 et 1 en entrée du réseau de neurones et en sortie, on aura une liste de 10 probabilités. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer une réseau de neurones avec 2 couches de neurones, constituées de 25 neurones pour la première, et de 10 neurones pour la deuxième (nos 10 résultats possibles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On définit les paramètres-clés de notre réseau de neurones artificiels\n",
    "n = 784 # nombre de prédicteurs (pixels) donnés en entrée du réseau\n",
    "h = 50 # nombre de neurones dans la première couche couche\n",
    "k = 10 # nombre de neurones dans la deuxième (dernière) couche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On crée notre réseau de neurones artificiels simplement en utilisant l'API de Keras\n",
    "model = Sequential() # initialisation\n",
    "model.add(Dense(h, input_dim= n)) # première couche de h neurones, prenant en entrée n prédicteurs (pixels)\n",
    "model.add(Activation('sigmoid')) # fonction d'activation de la première couche\n",
    "model.add(Dense(h)) # première couche de h neurones, prenant en entrée n prédicteurs (pixels)\n",
    "model.add(Activation('sigmoid')) # fonction d'activation de la première couche\n",
    "model.add(Dense(h)) # première couche de h neurones, prenant en entrée n prédicteurs (pixels)\n",
    "model.add(Activation('sigmoid')) # fonction d'activation de la première couche\n",
    "model.add(Dense(h)) # première couche de h neurones, prenant en entrée n prédicteurs (pixels)\n",
    "model.add(Activation('sigmoid')) # fonction d'activation de la première couche\n",
    "model.add(Dense(k)) # deuxième couche de k neurones\n",
    "model.add(Activation('softmax')) # fonction d'activation de la deuxième (dernière) couche\n",
    "model.compile(optimizer=optimizers.adam(lr=0.001), # compilation du réseau de neurones artificiels et définition de\n",
    "              loss='categorical_crossentropy',  # - la fonction de coût à minimiser\n",
    "              metrics=['accuracy'])             # - l'indicateur à afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du réseau de neurones avec les 60000 images de l'échantillon d'entraînement \n",
    "model.fit(normalized_images_train, encoded_labels_train, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a maintenant entraîné le réseau de neurones, qui devrait avoir une précision comprise entre 95% et 100% (pourcentage de prédictions correctes sur l'échantillon d'entraînement)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mesurer la performance de l'algorithme maintenant entraîné, on le teste sur les 10 000 images de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_test_pred_list = model.predict(normalized_images_test)\n",
    "\n",
    "# on affiche un exemple de prédiction\n",
    "random_num = np.random.randint(0,n_test)\n",
    "print(\"Exemple de prédiction pour une image de test choisie au hasard : \" + str(labels_test_pred_list[random_num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on pouvait s'y attendre, ces prédictions prennent la forme d'une liste de 10 probabilités. Pour obtenir une prédiction un peu plus \"interprétable\", on retient la position de l'élément de la liste ayant la plus haute probabilité. C'est cette position que le réseau de neurones juge la plus probable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(images, model):\n",
    "    normalized_images = scaler.transform(images)\n",
    "    labels_pred_list = model.predict(normalized_images)\n",
    "    labels_pred = [list(pred).index(max(pred)) for pred in labels_pred_list]\n",
    "    confiance = [max(pred) for pred in labels_pred_list]\n",
    "    return labels_pred, confiance\n",
    "\n",
    "labels_test_pred, confiance = predict(images_test, model)\n",
    "\n",
    "# on vérifie le résultat\n",
    "random_num = np.random.randint(0,n_test)\n",
    "print(\"La prédiction : \" + str(labels_test_pred_list[random_num]) + \\\n",
    "      \" correspond au label : \" + str(labels_test_pred[random_num]) + \\\n",
    "      \" avec un taux de confiance de \" + str(confiance[random_num]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant mesurer la précision des prédictions de l'algorithme sur l'échantillon de test avec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Le pourcentage de prédictions correctes est de \" + \\\n",
    "      str(round(accuracy_score(np.array(labels_test), labels_test_pred)*100,1)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons quelques résultats pour vérifier que la plupart des prédictions dont correctes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.sample(range(n_test), 100)\n",
    "f, axis = plt.subplots(10,10, figsize=(18,22))\n",
    "for i,ax in zip(random_idx, axis.flatten()):\n",
    "    aff_image(image = images_test[i], \\\n",
    "              title = \"Label : \" + str(labels_test[i]) + \"\\nPrédiction : \" + str(labels_test_pred[i]), \\\n",
    "              ax = ax)\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 3 - Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On importe les librairies dont on aura besoins\n",
    "from collections import Counter, deque # pour compter le nombre d'occurrence des éléments d'une liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on sépare les prédictions correctes des prédictions erronées\n",
    "corr_pred_idx = list(list(np.where(np.array(labels_test) - labels_test_pred == 0))[0])\n",
    "err_pred_idx = list(list(np.where(np.array(labels_test) - labels_test_pred != 0))[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons maintenant quelques résultats incorrects. Quel constat peut-on faire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = random.sample(err_pred_idx, min(100, len(err_pred_idx)))\n",
    "f, axis = plt.subplots(10,10, figsize=(15,20))\n",
    "for i,ax in zip(random_idx, axis.flatten()):\n",
    "    aff_image(image = images_test[i], \\\n",
    "              title = \"Label : \" + str(labels_test[i]) + \"\\nPrédiction : \" + str(labels_test_pred[i]), \\\n",
    "              ax = ax)\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va commencer par regarder sur quels chiffres l'algorithme se trompe le plus souvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_err_par_chiffre = np.array([Counter([labels_test[i] for i in err_pred_idx])[j] for j in range(0,10)])\n",
    "count_par_chiffres = np.array([Counter(labels_test)[j] for j in range(0,10)])\n",
    "percent_err_par_chiffre = count_err_par_chiffre/count_par_chiffres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(range(0,10),percent_err_par_chiffre)\n",
    "plt.xticks(range(0,10))\n",
    "plt.title(\"Fréquence d'erreurs par chiffre\")\n",
    "plt.ylabel(\"Fréquence d'erreurs\")\n",
    "plt.xlabel(\"Chiffre manuscrit\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "err_idx_par_chiffre = [list(np.where((np.array(labels_test) - labels_test_pred != 0) & \\\n",
    "                                         (np.array(labels_test) == i))[0]) for i in range(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "count_err_par_chiffre_par_chiffre_pred = [[Counter([labels_test_pred[i] \\\n",
    "                                           for i in err_idx_par_chiffre[k]])[j] \\\n",
    "                                           for j in range(0,10)] \\\n",
    "                                           for k in range(0,10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(count_err_par_chiffre_par_chiffre_pred, cmap= 'Reds')\n",
    "plt.yticks(range(0,10))\n",
    "plt.xticks(range(0,10))\n",
    "plt.ylabel(\"Chiffre réel\")\n",
    "plt.xlabel(\"Chiffre prédit\")\n",
    "plt.title(\"Chiffre réel vs chiffre prédit sur les prédictions erronées\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va essayer d'interpréter les décisions de l'algorithme pour comprendre les raisons de ses erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# on choisit une image pour laquelle l'algorithme a prédit que c'était un 3 alors que c'était un 5\n",
    "random_err_idx = random.choice([err_index for err_index in err_idx_par_chiffre[5] if labels_test_pred[err_index] == 3 ])\n",
    "random_err_image = np.array(images_test[random_err_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_image(image = random_err_image, \\\n",
    "          title = \"Label : \" + str(labels_test[random_err_idx]) + \"\\nPrédiction : \" + str(labels_test_pred[random_err_idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut afficher le taux de confiance de l'IA sur les erreurs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confiance_sur_erreur = [confiance[i] for i in err_pred_idx]\n",
    "confiance_sur_correct = [confiance[i] for i in corr_pred_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distr_confiance_sur_err = np.histogram(confiance_sur_erreur, [i/100 for i in range(0,101)])\n",
    "distr_confiance_sur_corr = np.histogram(confiance_sur_correct, [i/100 for i in range(0,101)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_distr_confiance_sur_err = distr_confiance_sur_err[0] / (distr_confiance_sur_corr[0] + distr_confiance_sur_err[0])\n",
    "per_distr_confiance_sur_corr = distr_confiance_sur_corr[0] / (distr_confiance_sur_corr[0] + distr_confiance_sur_err[0])\n",
    "per_distr_confiance_sur_err[np.isnan(per_distr_confiance_sur_err)] = 0\n",
    "per_distr_confiance_sur_corr[np.isnan(per_distr_confiance_sur_corr)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (20,8))\n",
    "plt.bar(distr_confiance_sur_corr[1][:-1] + 0.0075, per_distr_confiance_sur_err, width=0.008, label = \"erreur\", \\\n",
    "        color = 'red')\n",
    "plt.bar(distr_confiance_sur_corr[1][:-1] + 0.0075, per_distr_confiance_sur_corr, width=0.008, label = \"correct\", \\\n",
    "        bottom=per_distr_confiance_sur_err, color = 'green')\n",
    "plt.xlabel(\"Taux de confiance\")\n",
    "plt.ylabel(\"%age correct / erreur\")\n",
    "plt.xticks([i / 20 for i in range(0,21)])\n",
    "plt.xlim(0.5,1)\n",
    "plt.title(\"Vue des prédictions correctes / erronées par taux de confiance\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"En demandant à un humain de traiter manuellement les cas où l'IA est confiante à moins de 99%, \\\n",
    "on automatisera \" + str(round(len(np.where(np.array(confiance) > 0.99)[0])/10000*100,1)) + \"% des cas avec un taux d'erreur \\\n",
    "de l'IA de \" + str(round(per_distr_confiance_sur_err[-1]*100,1)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testons un peu la robustesse de l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on choisit une prédiction correcte au hasard\n",
    "random_corr_idx = random.choice(corr_pred_idx)\n",
    "random_corr_image = images_test[random_corr_idx]\n",
    "image_reshape = np.array(random_corr_image).reshape(28,28, order='C')\n",
    "plt.imshow(image_reshape, cmap='gray')\n",
    "\n",
    "# on rajoute le label en titre et on affiche le graphique\n",
    "plt.title(\"Label : \" + str(labels_test[random_corr_idx]) + \"\\nPrédiction : \" + str(labels_test_pred[random_corr_idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va tester la robustesse de l'algorithme lorsqu'on modifie l'image pour qu'elle soit noire sur fond blanc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_image = list(255 - np.array(random_corr_image))\n",
    "\n",
    "# on rajoute le label en titre et on affiche le graphique\n",
    "aff_image(image = rev_image, \\\n",
    "          title = \"Label : \" + str(labels_test[random_corr_idx]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, confiance = predict([rev_image], model)\n",
    "print(\"La prédiction de l'IA est \" + str(pred[0]) + \" avec une confiance de \" + str(round(confiance[0] * 100, 1)) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste maintenant la robustesse de l'algorithme lorsqu'on décale l'image de quelques pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pxl_shift = 5 # nombre de pixels dont on décale l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shift_image = list(np.array([np.roll(row, pxl_shift) for row in np.array(random_corr_image).reshape(28,28)]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axis = plt.subplots(1,2, figsize=(10,5))\n",
    "aff_image(random_corr_image, \"Image originale\", axis[0])\n",
    "aff_image(np.array(shift_image).flatten(), \"Image décalée\", axis[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, confiance = predict([shift_image], model)\n",
    "print(\"La prédiction de l'IA est \" + str(pred[0]) + \" avec une confiance de \" + str(round(confiance[0] * 100, 1)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
