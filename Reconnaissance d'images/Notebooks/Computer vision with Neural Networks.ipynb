{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision with neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Pré-requis : exécuter les cellules du fichier install.ipynb__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L'objectif est de construire et tester différents modèles de réseaux de neurones pour faire de la reconnaissance d'images, tout en prenant conscience de leurs limites.  \n",
    "#### Les parties 1 à 4 seront consacrées à la reconnaissance de chiffres manuscrits, tandis que la dernière partie sera consacrée à l'utilisation d'un algorithme pré-entraîné pour faire de la détection d'objets.  \n",
    "- #### Dans la partie 1 : nous travaillerons avec les données du problème de reconnaissance de chiffres manuscrits pour en comprendre le format et en évaluer la qualité\n",
    "- #### Dans la partie 2 : nous construirons un réseau de neurones artificiel pour reconnaître les chiffres manuscrits\n",
    "- #### Dans la partie 3 : nous construirons un réseau de neurones convolutionnel pour reconnaître les chiffres manuscrits\n",
    "- #### Dans la partie 4 : nous porterons un regard critique sur les résultats des réseaux de neurones développés\n",
    "- #### Dans la partie 5 : nous testerons un réseau de neurones pré-rentraîné bien plus puissant pour détecter des objets sur des images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"gray\">Partie 1 - Comprendre les données utilisées</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les librairies qui nous seront utiles pour cette partie :  \n",
    "- __MNIST__ : pour l'import de la base de données MNIST contenant 70 000 chiffres manuscrits  \n",
    "- __Numpy__ : pour travailler facilement des tableaux / matrices de données  \n",
    "- __Matplotlib__ : pour faire des graphiques    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist import MNIST\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les données du problème composées d'__images__ (img) de chiffres manuscrits et de __labels__ (lbl) indiquant le chiffre (compris entre 0 et 9) représenté sur l'image.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import des données brutes\n",
    "mndata = MNIST('../Resources/data')\n",
    "img_train_src, lbl_train_src = mndata.load_training()\n",
    "img_test_src, lbl_test_src = mndata.load_testing()\n",
    "\n",
    "# Reformattage des données importées sous forme de tableaux aux bonnes dimensions\n",
    "img_train = np.expand_dims(np.array([np.array(image).reshape(28,28) for image in img_train_src]),3)\n",
    "img_test = np.expand_dims(np.array([np.array(image).reshape(28,28) for image in img_test_src]),3)\n",
    "lbl_train = np.array(list(lbl_train_src))\n",
    "lbl_test = np.array(list(lbl_test_src))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a construit 4 jeux de données :\n",
    "- __img_train__ : images qui seront utilisées pour entraîner l'IA - _dimensions : (60000,28,28,1_)\n",
    "- __lbl_train__ : chiffres représentés sur les images de img_train - _dimensions : (60000,)_ (NB : le ième label correspond au label de la ième image)\n",
    "- __img_test__ : images qui seront utilisées pour tester l'IA - _dimensions : (10000,28,28,1)_\n",
    "- __lbl_test__ : chiffres représentés sur les images de img_test - _dimensions : (10000,)_ (NB : le ième label correspond au label de la ième image)  \n",
    "\n",
    "Chaque image est représentée par un tableau de 28x28x1 valeurs (28 lignes x 28 colonnes x 1 couleur) comprises entre 0 et 255 (les pixels).  \n",
    "Chaque valeur représente le niveau de gris d'un pixel (0 = noir, 255 = blanc)  \n",
    "\n",
    "On peut le vérifier avec le code suivant :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = len(img_train) # nombre d'images pour l'entraînement\n",
    "n_test = len(img_test) # nombre d'images pour le test\n",
    "\n",
    "print(\"Nombre d'images dans l'échantillon d'entraînement : {}\".format(n_train))\n",
    "print(\"Nombre d'images dans l'échantillon de test : {}\".format(n_test))\n",
    "print()\n",
    "print(\"Dimensions de img_train : {}\".format(img_train.shape))\n",
    "print(\"Dimensions de lbl_train : {}\".format(lbl_train.shape))\n",
    "print(\"Dimensions de img_test : {}\".format(img_test.shape))\n",
    "print(\"Dimensions de lbl_test : {}\".format(lbl_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensions d'une image : {}\".format(img_train[0].shape))\n",
    "print(\"Exemple de label d'une image : {}\".format(lbl_train[0]))\n",
    "print(\"Exemple de représentation d'une image : \\n{}\".format(np.matrix(img_train[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On crée une fonction *print_img* pour afficher plus visuellement les images avec lesquelles nous travaillerons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_img(image, title = \"\", ax = None):\n",
    "    if ax is None:\n",
    "        f, ax = plt.subplots(1,1)\n",
    "    ax.imshow(image.reshape(image.shape[0], image.shape[1]), cmap='gray')\n",
    "    ax.set_title(title)\n",
    "    if ax is None:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on teste la fonction print_img sur une image de la base de données d'entraînement\n",
    "idx = 1 # index de l'image à afficher\n",
    "\n",
    "print_img(image = img_train[idx], \\\n",
    "          title = \"Label : {}\".format(lbl_train[idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q1.1 : Que représentent les valeurs suivantes ?</font>\n",
    "- ### <font color=\"indigo\"> img_train[8764, 10, 20, 0]</font>\n",
    "- ### <font color=\"indigo\"> img_train[0, 0, 0, 0]</font>\n",
    "- ### <font color=\"indigo\">img_test[5487, 20, 15, 0]</font>\n",
    "- ### <font color=\"indigo\">img_test[11861, 8, 8, 0]</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q1.2 : Les données utilisées pour entraîner et tester l'IA sont cruciales pour créer une IA de bonne qualité. Quelle(s) analyse(s) peut-on faire sur les données d'entraînement et de test pour s'assurer que l'IA sera de bonne qualité et anticiper ses limites ? </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q12-Part1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q12-Part2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q1.3 : Au vu des résultats précédents, quelles limites de l'IA peut-on anticiper ? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"gray\">Partie 2 - Construction d'un réseau de neurones artificiel</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avant de définir les réseaux de neurones artificiels, introduisons ce qu'est un __neurone__.\n",
    "\n",
    "Un neurone est un \"objet\" informatique dont l'objectif est de __prédire un nombre $Y$ à partir de paramètres (ou prédicteurs) qu'on lui donne en entrée $I_{1}, ..., I_{N}$__. \n",
    "\n",
    "Il est composé de deux éléments :\n",
    "- Ses __coefficients__ $W_{1}, ..., W_{N}$ qui mesureront l'importance relative des prédicteurs $I_{1}, ..., I_{N}$ sur la prédiction à réaliser. Le neurone apprendra tout seul à ajuster ses coefficients grâce à la base de données à partir de laquelle on l'entraînera. \n",
    "- Sa __fonction d'activation__ (ou threshold) qui doit être une fonction non linéaire et qui permet essentiellement au neurone de résoudre des problèmes non linéaires.  \n",
    "_Exemples de fonctions d'activation connues : Sigmoïde, ReLu, SoftMax, ..._  \n",
    "\n",
    "Pour l'aider à adapter ses coefficients, on definit 3 éléments supplémentaires, qui sont communs à tous les algorithmes de Machine Learning supervisés :\n",
    "- Une __fonction de coût__ (loss function en anglais) qui permettra de mesurer à quel point les prédictions du neurone sont conformes à la réalité et qu'il s'agira de minimiser.  \n",
    "*Exemples de fonctions de coût connues : categorical_crossentropy, binary_crossentropy, mean_squared_error, mean_absolute_error, ...*\n",
    "- Une __fonction d'optimisation__ (optimizer en anglais) qui est un algorithme permettant d'adapter les coefficients du neurone $W_{1}, ..., W_{N}$ pour converger vers la solution qui minimise la fonction de coût.  \n",
    "_Exemples de fonctions d'optimisation connues : Adam, AdaDelta, SGD, ..._\n",
    "- Un __pas d'apprentissage__ (learning rate en anglais) qui permettra à la fonction d'optimisation de converger plus ou moins vite vers la solution qui minimise la fonction de coût (avec le risque si elle apprend trop vite de ne pas réussir à trouver la solution).\n",
    "\n",
    "Comment tout cela fonctionne en pratique ?  \n",
    "- Le neurone reçoit en entrée des paramètres $I_{1}, ..., I_{N}$ qui correspondent aux __prédicteurs__\n",
    "- Il effectue la combinaison linéaire des paramètres en entrée avec ses __coefficients__ $W_{1}, ..., W_{N}$ : $ W_{1}I_{1} + ... + W_{1}I_{N}$\n",
    "- Il applique à cette combinaison linéaire sa __fonction d'activation__ pour \"casser\" la linéarité et retourne un chiffre qui correspond à sa prédiction $\\widehat{Y} = \\sigma(W_{1}I_{1} + ... + W_{1}I_{N})$ (qu'il choisit au hasard au début)\n",
    "- Il compare sa prédiction $\\widehat{Y}$ avec la valeur attendue $Y$ dont il mesure la distance grâce à sa __fonction de coût__ $C(\\widehat{Y} - Y)$\n",
    "- En fonction de la distance entre sa prédiction et la valeur attendue, de sa __fonction d'optimisation__ et de son __pas d'apprentissage__, il ajuste ses __coefficients__ $W_{1}, ..., W_{N}$.\n",
    "- Il réitère l'ensemble des étapes ci-dessus sur chaque donnée d'entraînement, par __batch__ de données d'entraînement pour accélérer les calculs\n",
    "- Il réitère l'ensemble des étapes ci-dessus sur toute la base de données d'entraînement autant de fois que souhaité par l'utilisateur. on parle de nombre d'__epochs__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Représentation d'un neurone* |\n",
    "|:--:|\n",
    "|![](../Resources/images/Neurone.jpg)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un seul neurone n'est souvent pas suffisant pour obtenir de bons résultats car il ne calcule des coefficient que sur chaque paramètre d'entrée _pris individuellement_.   \n",
    "\n",
    "On construit donc une architecture de neurones appelée __réseau de neurones artificiel__ qui va multiplier les possibilités de combinaisons des paramètres d'entrée. Un réseau de neurones artificiel est composé d'une ou plusieurs couche(s) de neurones, chacune comprenant plusieurs neurones. Chaque neurone peut alors envoyer son résultat à d'autres neurones.  \n",
    "\n",
    "Par souci de cohérence, chaque neurone d'une même couche aura __la même fonction d'activation__. \n",
    "\n",
    "On applique alors à cette architecture __une fonction de coût, fonctions d'optimisation et un pas d'apprentissage__, qui permettront à chacun des neurones de la structure d'adapter leurs coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Exemple de réseau de neurones à deux couches* |\n",
    "|:--:|\n",
    "|![](../Resources/images/Réseau de neurones.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette architecture, un peu \"bourrine\", est toutefois redoutablement efficace, comme nous allons le voir !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer, on importe __keras__, qui est une librairie facile à utiliser pour créer des réseaux de neurones et qui repose sur __tensorflow__, librairie développée par Google pour faire du Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.1 : Pour notre problème, quels paramètres devra prendre notre réseau de neurones en entrée et combien y en aura-t-il ?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.2 : Combien de neurones doit-il y avoir dans la dernière couche ? Quelle sera la forme de la sortie du réseau de neurones ?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.3 : Comment doit-on modifier les labels des images pour entraîner le réseau correctement ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q23.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.4 : Comment interpréter le résultat que le réseau donnera ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q24.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.5 : Pour que le réseau apprenne correctement, il est préférable que les données soient centrées autour de 0 et qu'elles aient une déviation standard d'environ 1. Pourquoi ? </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on centre les données sur zéros et on définit la déviation standard à 1\n",
    "norm = ImageDataGenerator(featurewise_center= True, \\\n",
    "                          featurewise_std_normalization= True)\n",
    "\n",
    "norm.fit(img_train)\n",
    "norm_img_train = norm.flow(x= img_train, \n",
    "                           batch_size= n_train, \n",
    "                           shuffle= False).next()\n",
    "\n",
    "norm_img_test = norm.flow(x= img_test,\n",
    "                          batch_size= n_test,\n",
    "                          shuffle= False).next()\n",
    "\n",
    "# on vérifie le résultat\n",
    "print(\"Moyenne de l'échantillon d'entraînement : {:.2}\".format(norm_img_train.mean()))\n",
    "print(\"Déviation standard de l'échantillon d'entraînement : {:.2}\".format(norm_img_train.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes maintenant prêts pour créer notre réseau de neurones. Nous allons commencer par un réseau de neurones ayant les caractéristiques suivantes : \n",
    "- l'__architecture__ du réseau sera composée de 2 couches de neurones, constituées de 50 neurones pour la première, et de 10 neurones pour la deuxième\n",
    "- la __fonction d'activation__ sera une fonction sigmoïde pour la première couche et un softmax pour la deuxième couche\n",
    "- la __fonction de coût__ sera une fonction logarithmique\n",
    "- la __fonction d'optimisation__ sera SGD\n",
    "- le __pas d'apprentissage__ sera de 0.001    \n",
    "\n",
    "Enfin, on entraînera le réseau de neurones par __batch de 32 images__ avec __10 epochs__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On définit les paramètres-clés de notre réseau de neurones artificiels\n",
    "input_shape = (28, 28, 1)                  # dimension des prédicteurs donnés en entrée du réseau\n",
    "hidden_layer_size = 50                     # nombre de neurones dans la première couche couche\n",
    "last_layer_size = 10                       # nombre de neurones dans la deuxième (dernière) couche\n",
    "activation_function = 'sigmoid'            # fonction d'activation de la première couche\n",
    "optimizer = optimizers.SGD                 # fonction d'optimisation\n",
    "learning_rate = 0.001                      # pas d'apprentissage\n",
    "loss_function = 'categorical_crossentropy' # fonction de coût\n",
    "batch_size = 32                            # taille des batch d'entraînement\n",
    "nb_epochs = 10                             # nombre d'itérations sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On crée notre réseau de neurones artificiels simplement en utilisant l'API de Keras\n",
    "\n",
    "ann = Sequential() # initialisation du réseau de neurones artificiels (artificial neural network)\n",
    "\n",
    "ann.add(Flatten(input_shape = input_shape)) # on transforme les images en une liste de 28x28=784 données\n",
    "\n",
    "ann.add(Dense(hidden_layer_size)) # première couche de 'hidden_layer_size' neurones\n",
    "ann.add(Activation(activation_function)) # fonction d'activation de la première couche\n",
    "\n",
    "ann.add(Dense(last_layer_size)) # deuxième (dernière) couche de 'last_layer_size' neurones\n",
    "ann.add(Activation('softmax')) # fonction d'activation de la deuxième (dernière) couche\n",
    "\n",
    "ann.compile(optimizer=optimizer(lr=learning_rate), # compilation du réseau de neurones artificiels\n",
    "            loss=loss_function,   # - la fonction de coût à minimiser\n",
    "            metrics=['accuracy']) # - l'indicateur à afficher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement du réseau de neurones avec les 60000 images de l'échantillon d'entraînement\n",
    "# centrées autour de 0 et standardisées, avec les labels vectorisés\n",
    "\n",
    "history = ann.fit(norm_img_train, vec_lbl_train, epochs=nb_epochs, batch_size=batch_size, \\\n",
    "                  validation_data=(norm_img_test, vec_lbl_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Différents indicateurs sont calculés pour chaque epochs :\n",
    "- __loss__ : valeur de la fonction de coût sur l'échantillon d'entraînement après l'epoch (doit être la plus petite possible)\n",
    "- __acc__ (pour __accuracy__) : précision de l'algorithme sur l'échantillon d'entraînement (qui correspond au nombre de prédictions correctes sur le nombre d'images d'entraînement)\n",
    "- __val_loss__ (pour __validation_accuracy__) : valeur de la fonction de coût sur l'échantillon de test\n",
    "- __val_acc__ (pour __validation_accuracy__) : précision de l'algorithme sur l'échantillon de test (qui correspond au nombre de prédictions correctes sur le nombre d'images de test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.6 : Sur quels paramètres peut-on jouer pour tenter d'améliorer la précision du modèle ? Essayez d'améliorer le modèle sans toucher les paramètres *batch_size* et *nb_epochs*.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut tracer l'historique des précisions sur les échantillons d'entraînement et de test après chaque epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title(\"Précision de l'algorithme\")\n",
    "    plt.ylabel('Précision')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.7 : Que remarque-t-on ? (optionnel) Comment améliorer le résultat ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q27.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons quelques résultats pour vérifier que la plupart des prédictions sont correctes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(images, nn, norm):\n",
    "# Evalue la prédiction du réseau de neurones 'nn'\n",
    "# sur les images 'images' (dimensions (,28,28,1)),\n",
    "# normées avec le générateur 'norm\n",
    "    norm_img = norm.flow(x=images, batch_size=len(images), shuffle=False).next()\n",
    "    nn_outputs = nn.predict(norm_img)\n",
    "    prediction = [nn_output.argmax() for nn_output in nn_outputs]\n",
    "    confidence = [max(nn_output) for nn_output in nn_outputs]\n",
    "    return prediction, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, confidence = predict(images = img_test, nn = ann, norm = norm)\n",
    "\n",
    "random_idx = np.random.choice(range(0,n_test), 100) # on choisit 100 images de test au hasard\n",
    "\n",
    "# On affiche les images et les prédictions associées\n",
    "f, axis = plt.subplots(10,10, figsize=(18,25))\n",
    "for i,ax in zip(random_idx, axis.flatten()):\n",
    "    print_img(image = img_test[i], \\\n",
    "              title = \"Label : {}\\nPrédiction : {}\\nConf : {:.1%}\".format(lbl_test[i], prediction[i], confidence[i]),\n",
    "              ax = ax)\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q2.8 : Quelles sont les principales limites d'un réseau de neurones artificiel ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"gray\">Partie 3 - Construction d'un réseau de neurones convolutionnel</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un __réseau de neurones convolutionnel__, utilisé pour la première fois par Yann LeCun et ses équipes (sur ce même problème de reconnaissance de chiffres manuscrits) est particulièrement adapté à la reconnaissance d'images. Il est  composé de deux parties :\n",
    "- __Feature learning__ : cette partie permet l'apprentissage des caractéristiques pertinentes de l'image (contours, contrastes, formes, ...).\n",
    "- __Classification__ : cette partie constituée d'un réseau de neurones artificiel, tel que décrit dans la dernière partie, permet d'apprendre à prédire ce que l'image représente, mais plus cette fois-ci à partir des images brutes, mais à partir des images filtrées dans la phase de feature learning.  \n",
    "\n",
    "La phase de __feature learning__ comprend deux étapes, qui peuvent être répétées autant de fois que nécessaire :\n",
    "- __Convolution__ : apprentissage et application de filtres pemettant de mettre en avant les caractéristiques de l'image (contours, contrastes, formes, ...). Ces filtres sont représentés par des matrices de taille précisée par l'utilisateur et dont les coefficients vont être appris par l'algorithme, de la même manière que les coefficients d'un réseau de neurones artificiel sont appris par l'algorithme construit dans la partie 2.  \n",
    "Les filtres sont appliqués sur une image comme illustré sur le schéma ci-dessous :  \n",
    "\n",
    "$$Filtre : \\begin{pmatrix} 0 & 1 & 2 \\\\ 2 & 2 & 0 \\\\ 0 & 1 & 2 \\end{pmatrix}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Convolution d'une image 5x5 par le filtre 3x3 indiqué ci-dessus* |\n",
    "|:--:|\n",
    "|![](../Resources/images/Convolution.gif)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- __Pooling__ : réduction de la dimension de l'image (pour accélérer les calculs) en appliquant le Max ou la Moyenne des pixels de chaque partie de l'image.  \n",
    "Le pooling s'effectue sur une image comme illustré sur le schéma ci-dessous (ici MaxPooling 2x2 avec un pas de 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Exemple de MaxPooling sur une image 4x4* |\n",
    "|:--:|\n",
    "|![](../Resources/images/Pooling.jpg)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois la phase de feature learning réalisée, les pixels de l'image ainsi traitée sont envoyés dans le réseau de neurones artificiels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Exemple d'architecture d'un réseau de neurones convolutionnel* |\n",
    "|:--:|\n",
    "|![](../Resources/images/cnn.PNG)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On importe les fonctions dont on aura besoin pour l'étape de feature learning\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q3.1 : Effectuer la convolution de l'image : $$\\begin{pmatrix} 2 & 3 & 0 & 0 \\\\ -1 & 1 & 3 & 1 \\\\ 0 & 1 & 2 & -1 \\\\ -1 & 0 & 0 & 1 \\end{pmatrix}$$ par le filtre : $$\\begin{pmatrix} 1 & -1 \\\\ -2 & 0 \\end{pmatrix}$$  et appliquer un MaxPooling 2x2 avec un pas de 1 au résultat.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image = np.expand_dims(np.array([\n",
    "        [ 2,  3,  0,  0],\n",
    "        [-1,  1,  3,  1],\n",
    "        [ 0,  1,  2, -1],\n",
    "        [-1,  0,  0,  1]]), -1)\n",
    "\n",
    "kernel = np.array([\n",
    "        [ 1., -1.],\n",
    "        [-2.,  0.],\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q31.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichons un exemple d'application de filtres à une image de notre base de données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# quelques filtres connus\n",
    "identity_kernel = np.array([\n",
    "        [ 0.0,  0.0,  0.0],\n",
    "        [ 0.0,  1.0,  0.0],\n",
    "        [ 0.0,  0.0,  0.0]])\n",
    "\n",
    "outline_kernel = np.array([\n",
    "        [-1.0, -1.0, -1.0],\n",
    "        [-1.0,  8.0, -1.0],\n",
    "        [-1.0, -1.0, -1.0]])\n",
    "\n",
    "blur_kernel = np.array([\n",
    "        [ 1.0,  1.0,  1.0],\n",
    "        [ 1.0,  1.0,  1.0],\n",
    "        [ 1.0,  1.0,  1.0]])\n",
    "\n",
    "horizontal_kernel = np.array([\n",
    "        [ 0.0,  1.0,  0.0],\n",
    "        [ 0.0,  -1.0,  0.0],\n",
    "        [ 0.0,  0.0,  0.0]])\n",
    "\n",
    "vertical_kernel = np.array([\n",
    "        [ 0.0,  0.0,  0.0],\n",
    "        [ 1.0,  -1.0,  0.0],\n",
    "        [ 0.0,  0.0,  0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img_train[1000]\n",
    "maxpooling = False\n",
    "\n",
    "f, axis = plt.subplots(2,3, figsize=(8,5))\n",
    "print_img(img, title = \"Image originale\", ax = axis[0,0])\n",
    "print_img(conv(img, identity_kernel, maxpooling), title = \"Identity kernel\", ax = axis[0,1])\n",
    "print_img(conv(img, outline_kernel, maxpooling), title = \"Outline kernel\", ax = axis[0,2])\n",
    "print_img(conv(img, blur_kernel, maxpooling), title = \"Blur kernel\", ax = axis[1,0])\n",
    "print_img(conv(img, horizontal_kernel, maxpooling), title = \"Horizontal kernel\", ax = axis[1,1])\n",
    "print_img(conv(img, vertical_kernel, maxpooling), title = \"Vertical kernel\", ax = axis[1,2])\n",
    "\n",
    "for ax in axis.flatten(): ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant créer notre réseau de neurones convolutionnel. Il sera composé de :\n",
    "- Feature learning : 2 couches de Convolution apprenant respectivement 64 et 128 filtres 3x3, avec une fonction d'activation relu + MaxPooling 2x2 (avec un pas de 2)\n",
    "- Classification : même architecture que le réseau de neurones artificiel mis au point dans la partie 2\n",
    "\n",
    "Les fonctions de coût sera identique à celle de la partie 2, la fonction d'optimisation et le pas d'apprentissage seront identique à la partie 2.\n",
    "\n",
    "Enfin, le réseau de neurones convolutionnel sera entraîné par batch de 32 images, sur seulement 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On définit les paramètres-clés de notre réseau de neurones convolutionnel\n",
    "input_shape = (28, 28, 1)                  # dimension des prédicteurs donnés en entrée du réseau\n",
    "conv_1_layer_size = 64                     # nombre de filtres de la première couche de convolution\n",
    "conv_2_layer_size = 128                    # nombre de filtres de la deuxième couche de convolution\n",
    "filter_size = (3,3)                        # dimension des filtres\n",
    "pool_size = (2,2)                          # dimension de la fenêtre de MaxPooling\n",
    "pool_stride = 2                            # pas du MaxPooling\n",
    "optimizer = optimizers.adadelta            # fonction d'optimisation\n",
    "learning_rate = 1                          # pas d'apprentissage\n",
    "loss_function = 'categorical_crossentropy' # fonction de coût\n",
    "batch_size = 32                            # taille des batch d'entraînement\n",
    "nb_epochs = 3                              # nombre d'itérations sur les données d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "cnn = Sequential()\n",
    "\n",
    "# Création des couches de feature learning\n",
    "cnn.add(Conv2D(conv_1_layer_size,                # Première convolution\n",
    "               kernel_size = filter_size,        \n",
    "               activation = activation_function, \n",
    "               input_shape = input_shape))       \n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size = pool_size,      # Premier MaxPooling\n",
    "                     strides = pool_stride))   \n",
    "\n",
    "cnn.add(Conv2D(conv_2_layer_size,                # Deuxième convolution\n",
    "               kernel_size = filter_size,\n",
    "               activation = activation_function)) \n",
    "\n",
    "cnn.add(MaxPooling2D(pool_size = pool_size,      # Deuxième MaxPooling\n",
    "                     strides = pool_stride))   \n",
    "\n",
    "# Création des couches d'apprentissage (réseau de neurones artificiel)\n",
    "### Copier ici la structure du réseau de neurones artificiel utilisé dans la partie 2\n",
    "###\n",
    "###\n",
    "\n",
    "# Compilation\n",
    "cnn.compile(optimizer=optimizer(lr = learning_rate),\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q3.2 : Combien de paramètres y a-t-il en entrée du réseau de neurones artificiel ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On entraîne le réseau de neurones convolutionnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.fit(norm_img_train, vec_lbl_train, batch_size=batch_size, epochs = nb_epochs, \\\n",
    "          validation_data=(norm_img_test, vec_lbl_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche quelques résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction, confidence = predict(images = img_test, nn = cnn, norm = norm)\n",
    "\n",
    "random_idx = np.random.choice(range(0,n_test), 100) # on choisit 100 images de test au hasard\n",
    "\n",
    "f, axis = plt.subplots(10,10, figsize=(18,25))\n",
    "for i,ax in zip(random_idx, axis.flatten()):\n",
    "    print_img(image = img_test[i], \\\n",
    "              title = \"Label : {}\\nPrédiction : {}\\nConf : {:.1%}\".format(lbl_test[i], prediction[i], confidence[i]),\n",
    "              ax = ax)\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour mieux comprendre comment fonctionnent les réseaux de neurones convolutionnels, on peut visualiser les sorties des 4 premières couches du réseau. C'est la dernière qui sera envoyée au réseau de neurones artificiel et qui remplace donc l'image originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1000 # index de l'image sur laquelle visualiser les résultats\n",
    "img = np.expand_dims(img_test[idx], 0)\n",
    "norm_img = norm.flow(x=img, batch_size=len(img), shuffle=False).next()\n",
    "\n",
    "def display_feature_map(layer, figsize = (20,5), nn = cnn, norm = norm):\n",
    "    # fonction affichant toutes les images à la sortie de la couche 'layer' du réseau 'nn'\n",
    "    print(nn.get_layer(index = layer).name)\n",
    "    \n",
    "    layer_cnn = Model(inputs=nn.inputs, outputs=nn.layers[layer].output)\n",
    "    pred = layer_cnn.predict(norm_img)\n",
    "    layer_output_size = pred.shape[-1]\n",
    "\n",
    "    fig, axis = plt.subplots(int(layer_output_size/16), 16, figsize=figsize)\n",
    "    for i,ax in zip(range(0, layer_output_size), axis.flatten()):\n",
    "        print_img(image = pred[0,:,:,i], title=\"\", ax = ax)\n",
    "        ax.set_axis_off()\n",
    "    plt.show()\n",
    "    \n",
    "# On affiche les images à la sortie des 4 premuères couches\n",
    "for i in range(0,4):\n",
    "    if i < 2 :\n",
    "        figsize = (20,5)\n",
    "    else:\n",
    "        figsize = (20,10)\n",
    "    display_feature_map(layer = i, figsize=figsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"gray\">Partie 4 - Critiques des résultats</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les librairies dont on aura besoin :\n",
    "- __Lime__ : librairie très récente pour visualiser les facteurs d'influence les plus importants qui peuvent expliquent une décision d'une l'IA\n",
    "- __Scikit-Learn__ : une librairie très utilisée en Machine Learning que nous utiliserons ici pour calculer des indicateurs de performance de l'algorithme\n",
    "- __Scikit-Image__ : une librairie qui permet de travailler facilement avec les images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lime\n",
    "from lime import lime_image\n",
    "from lime.wrappers.scikit_image import SegmentationAlgorithm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.color import gray2rgb, rgb2gray, label2rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On charge les prédictions du réseau de neurones convolutionnel et on sépare les prédictions correctes des prédictions erronées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les résultats du réseau de neurones convolutionel\n",
    "prediction, confidence = predict(images = img_test, nn = cnn, norm = norm)\n",
    "\n",
    "# On sépare les prédictions correctes des prédictions erronées\n",
    "corr_idx = np.where(lbl_test - prediction == 0)[0]  # index des prédictions correctes\n",
    "err_idx = np.where(lbl_test - prediction != 0)[0]   # index des prédictions erronées\n",
    "print(\"Il y a {} erreurs de l'IA dans l'échantillon de test.\".format(len(err_idx)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On affiche les prédictions erronées (maximum 100 affichées) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axis = plt.subplots(10,10, figsize=(18,28))\n",
    "for i,ax in zip(err_idx, axis.flatten()):\n",
    "    print_img(image = img_test[i], \\\n",
    "              title = \"Label : {}\\nPrédiction : {}\\nConf : {:.1%}\\nIndex : {}\"\\\n",
    "                      .format(lbl_test[i], prediction[i], confidence[i], i),\n",
    "              ax = ax)\n",
    "    ax.set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q4.1 : Quels constats peut-on faire ? Quelles analyses peut-on faire pour mieux caractériser les erreurs de l'IA ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q41-Hint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q41-Part1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q41-Part2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q4.2 : Sans toucher à l'algorithme, que peut-on faire pour minimiser les erreurs de l'IA ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q42-Hint.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q42.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va maintenant essayer de comprendre les prédictions erronées de l'algorithme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# On construit les objets qui permettront d'afficher les pixels les plus importants pour l'IA\n",
    "explainer = lime_image.LimeImageExplainer(verbose = False)\n",
    "segmenter = SegmentationAlgorithm('quickshift', kernel_size=1, max_dist=200, ratio=0.2)\n",
    "\n",
    "def predict_for_lime(img_rgb, nn = cnn, norm = norm):\n",
    "    images = np.expand_dims((rgb2gray(img_rgb)*255).astype('uint8'),3)\n",
    "    norm_img = norm.flow(x=images, batch_size=len(images), shuffle=False).next()\n",
    "    prediction = nn.predict(norm_img)\n",
    "\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1000 # index de l'image à analyser\n",
    "\n",
    "img = img_test[idx]\n",
    "img_rgb = gray2rgb(img.reshape(28,28)).astype('uint8')\n",
    "\n",
    "explanation = explainer.explain_instance(img_rgb, \n",
    "                                         classifier_fn = predict_for_lime, \n",
    "                                         top_labels=10, hide_color=0, num_samples=10000, segmentation_fn=segmenter)\n",
    "\n",
    "fig, axis = plt.subplots(2,5, figsize = (20,8))\n",
    "for i, ax in enumerate(axis.flatten()):\n",
    "    temp, mask = explanation.get_image_and_mask(i, positive_only=True, num_features=10, hide_rest=False, min_weight = 0.)\n",
    "    ax.imshow(label2rgb(mask,image=temp, bg_label = 0, alpha=0.6, colors=['green']))\n",
    "    ax.set_title(\"Label : \" + str(lbl_test[idx]) + \\\n",
    "                 \"\\nPrédiction : \"+ str(i))\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q4.3 : A partir des intuitions développées dans les partie 1 et des résultats précédents de LIME, comment peut-on modifier les images pour tromper l'algorithme ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx = 1000\n",
    "img = np.array(img_test[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q43-Part1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q43-Part2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q43-Part3.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q4.4 : Comment améliorer la robustesse de l'algorithme ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../Solutions/Q44.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, rotation_range = 25, width_shift_range = 0.2, height_shift_range=0.2, zoom_range=0.2)\n",
    "#datagen.fit(img_train)\n",
    "#iterator = datagen.flow(img_train, vec_lbl_train, batch_size = 10)\n",
    "#norm_img_test_aug = datagen.flow(img_test, shuffle = False, batch_size = 10000).next()\n",
    "#cnn.fit_generator(iterator, epochs=4, steps_per_epoch=60000, validation_data=(norm_img_test_aug, vec_lbl_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"gray\">Partie 5 - Utilisation d'un réseau de neurones convolutionnel puissant</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on a pu le constater, nos ordinateurs peinent déjà à construire un réseau de neurones convolutionnel \"simple\" sur des images de 28x28 pixels.  \n",
    "Heureusement, il existe sur le marché des réseaux de neurones autrement plus \"profonds\" pré-entraînés sur des millions d'images.  \n",
    "C'est notamment le cas de l'algorithme ResNet dont les architectures sont présentés ci-dessous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| *Architecture des réseaux ResNet* |\n",
    "|:--:|\n",
    "|![](../Resources/images/ResNet.png)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons dans cette partie utiliser l'algorithme Mask-RCNN qui combine ResNet101 comme réseau de neurones convolutionnel et un puissant algorithme de segmentation d'images. Mask-RCNN est ainsi capable de détecter des objets sur une image.  \n",
    "\n",
    "A l'heure actuelle, l'algorithme est capable de détecter les objets de la liste *class_names* ci-dessous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = ['BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane',\n",
    "               'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "               'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird',\n",
    "               'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear',\n",
    "               'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie',\n",
    "               'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "               'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "               'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',\n",
    "               'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "               'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "               'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed',\n",
    "               'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote',\n",
    "               'keyboard', 'cell phone', 'microwave', 'oven', 'toaster',\n",
    "               'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors',\n",
    "               'teddy bear', 'hair drier', 'toothbrush']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe les librairies que nous utiliserons dans cette partie :\n",
    "- __Mask RCNN__ : pour utiliser l'algorithme Mask-RCNN\n",
    "- __OpenCV__ : pour prendre des photos à l'aide de la webcam de l'ordinateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../') # pour se positionner dans le bon dossier pour importer mrcnn\n",
    "import Resources.maskrcnn.mrcnn as mrcnn\n",
    "from mrcnn import config, visualize\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "import cv2\n",
    "\n",
    "# On configure Mask-RCNN pour qu'il fonctionne sur notre ordinateur\n",
    "class InferenceCocoConfig(config.Config):\n",
    "    NAME = \"inference_coco\"\n",
    "    NUM_CLASSES = 1 + 80  # COCO has 80 classes\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "\n",
    "config = InferenceCocoConfig()\n",
    "model = modellib.MaskRCNN(mode=\"inference\", model_dir='logs', config=config)\n",
    "\n",
    "# On charge les coefficients du réseau de neurones sous-jacent à Mask-RCNN\n",
    "coco_model_file = \"../Resources/maskrcnn/mask_rcnn_coco.h5\"\n",
    "model.load_weights(coco_model_file, by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour tester l'algorithme, on va utiliser des photos directement prises avec la webcam de notre ordinateur.  \n",
    "On définit donc la fonction *camera_grab* pour cela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def camera_grab(camera_id=0):\n",
    "    camera = cv2.VideoCapture(camera_id)\n",
    "    try:\n",
    "        for i in range(10):\n",
    "            snapshot_ok, image = camera.read()\n",
    "        if snapshot_ok:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            print(\"WARNING: could not access camera\")\n",
    "    finally:\n",
    "        camera.release()\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On prend une photo avec notre webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic = camera_grab()\n",
    "plt.imshow(pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On teste l'algorithme Mask-RCNN avec notre photo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(picture):\n",
    "    results = model.detect([picture], verbose=0)\n",
    "    r = results[0]\n",
    "    visualize.display_instances(pic, r['rois'], r['masks'], r['class_ids'], class_names, r['scores'])\n",
    "    \n",
    "detect(pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi utiliser une image sauvegardée sur notre disque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.getcwd() # pour afficher le chemin actuel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pic_path = \"/Users/hugofayolle/Documents/Python/Cours/Cours Accenture/Reconnaissance d'images/Resources/maskrcnn/images/\"\n",
    "pic_filename = '12283150_12d37e6389_z.jpg'\n",
    "\n",
    "pic = plt.imread(pic_path+pic_filename)\n",
    "detect(pic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"indigo\">Q5.1 : Comment ce type d'algorithme pré-entraîné peut-il être utilisé dans l'industrie ?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_course",
   "language": "python",
   "name": "deep_learning_course"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
